% This file was created (at least in part) by the script ParseMdtoLatex by Louis du Plessis
% (Available from https://github.com/taming-the-beast)

\documentclass[11pt]{article}
\input{preamble}

% Add your bibtex library here
\addbibresource{master-refs}


%%%%%%%%%%%%%%%%%%%%
% Do NOT edit this %
%%%%%%%%%%%%%%%%%%%%
\begin{document}
\renewcommand{\headrulewidth}{0.5pt}
\headsep = 20pt
\lhead{ }
\rhead{\textsc {BEAST v2 Tutorial}}
\thispagestyle{plain}


%%%%%%%%%%%%%%%%%%
% Tutorial title %
%%%%%%%%%%%%%%%%%%
\begin{center}

	% Enter the name of your tutorial here
	\textbf{\LARGE Model adequacy using BEAST2}\\\vspace{2mm}

	% Enter a short description of your tutorial here
	\textbf{\textcolor{mycol}{\Large Assessing clock and substitution models}}\\

	\vspace{4mm}

	% Enter the names of all the authors here
	{\Large {\em David Duchêne}}
\end{center}


%%%%%%%%%%%%%%%%%
% Tutorial body %
%%%%%%%%%%%%%%%%%

\section{Background}\label{background}

This tutorial will guide you through methods to assess model adequacy in
BEAST v2.4.2. In common practice, evolutionary
models are selected based on their statistical fit \emph{relative to
each other}. This might be sufficient in some cases, but there is a risk
that all of the candidate models lead to inferences that poorly
represent the true evolutionary process. Indeed, even the most complex
or best fitting model from a set of candidates can produce highly
erroneous estimates of parameters of interest. In this tutorial we will
explore methods to investigate the absolute merits of the model. This
kind of assessment of the absolute performance of models is also known
as model checking or assessment of model adequacy or plausibility.

Before starting the tutorial, it is important that you understand the
methods used in Bayesian inference for assessing model adequacy. A
typical assessment of model adequacy is done by comparing a test
statistic, calculated from the empirical data set, with the values of
the statistic calculated from a large number of data sets simulated
under the model. The simulated data from the model are often referred to
as posterior predictive simulations (PPS), and they represent future or
alternative data sets under the candidate model. The test statistic
should be informative about the assumptions of the model in question.

A large number of test statistics have been proposed to assess the
components of phylogenetic analyses. In this tutorial we will
investigate two test statistics, one for assessing the substitution
model, and one for assessing the priors on rates and times used for
molecular dating (Figure \ref{fig:example1}).

\begin{itemize}

\item
  The multinomial likelihood, which is the likelihood of the data under
  a model with only a single general assumption: that substitution
  events are independent and identically distributed. This statistic can
  be used to assess overall substitution model fit. Note that sites with
  missing data or indels should not be included when estimating the
  multinomial likelihood.
\item
  The $ A $ index assesses the power of the molecular-clock
  model to estimate the number of substitutions across branches,
  assuming a tree topology and an adequate substitution model. We will
  go through this statistic in more detail during this exercise.
\end{itemize}

\section{Programs used in this
Exercise}\label{programs-used-in-this-exercise}

\begin{itemize}

\item
  BEAST v2.4.2.
\item
  R programming environment.
\item
  R packages \emph{ape} and \emph{phangorn}. Before starting the exercise, install these packages by typing the following in your R console:

      \begin{lstlisting}[language=R]
      install.packages("phangorn", dependencies = T)
      \end{lstlisting}

\end{itemize}

\clearpage

\section{Run the empirical
data}\label{run-the-empirical-data}

In the \lstinline!data! folder you will find a simulated sequence
alignment with 2000 nucleotides in nexus format (\lstinline!al.1.nex!)
and a Yule-process chronogram in newick format (\lstinline!chron.tre!)
with 50 taxa. The alignment was simulated along the chronogram under a
Jukes-Cantor substitution model and an \textbf{uncorrelated log-normal clock model}. You will also find an XML file (\lstinline!sim.1.xml!) in the
\lstinline!xml! folder to run BEAST 2 for this data set. The settings in this XML file include a Jukes-Cantor substitution model, a \textbf{strict clock}, a birth-death tree prior, and a normally distributed root calibration with standard deviation of 5 and an offset of 50.

Importantly, this XML file has been modified directly such that the starting tree has been provided and it remains fixed throughout the run. Continue in this section if you wish to learn how to modify the XML, or proceed to the next section to assess model adequacy. 

Load the data \lstinline!al.1.nex! to BEAUti, setting the model as described above, and saving the XML file. Then open the XML file in your preferred text editor, and add a \lstinline!tree! statement as follows above line with the \lstinline!<run ...! statement.

\begin{lstlisting}[language=XML]
    <tree id="Tree.t:al" spec='beast.util.TreeParser' newick="((A, B), (C, D), E);" taxa="@al"/>
\end{lstlisting}

Make sure that the newick tree is correct (you will find this in \lstinline!chron.tre! in the \lstinline!data! folder). Also make sure that the names of the tree and the taxa are correct. You will find the name of your tree after \lstinline!"Tree.t:! elsewhere in the XML. The name of the taxa is an \lstinline!@! followed by your data \lstinline!id! as shown immediately above the alignment.

Now remove the \lstinline!tree! statement, which is inside the \lstinline!state! and looks like the following.

\begin{lstlisting}[language=XML]
    <tree id="Tree.t:treename" name="stateNode">
            <taxonset id="TaxonSet.alignmentname" spec="TaxonSet">
                <alignment idref="alignmentname"/>
            </taxonset>
     </tree>
\end{lstlisting}

In the place of that \lstinline!tree! statement, type an \lstinline!input! statement, which will lead  to a new \lstinline!statenode! as follows.

\begin{lstlisting}[language=XML]
    <input name='stateNode' idref='Tree.t:treename'/>
\end{lstlisting}

Once again, make sure that the tree name is correct.

Now remove the whole random tree initialiser, which begins and ends with the following lines.

\begin{lstlisting}[language=XML]
    <init id="RandomTree.t:treename" ...
    ...
    </init>
\end{lstlisting}

Lastly, remove the lines (or set the weights to 0) of the operators on the tree topology. These include the lines that have any of \lstinline!SubtreeSlide!, \lstinline!Narrow!, \lstinline!Wide!, and \lstinline!WilsonBalding!. You might find these words together with the tree model selected (in this case \lstinline!BirthDeath!).

Now run the XML file using BEAST 2. The output
of this run can also be found in the folder \lstinline!precooked_runs!.

\section{One step model assessment}\label{one-step-model-assessment-exercise}

In this section we will run substitution and clock model assessment, using the output from the BEAST 2 analysis that we ran in the previous section. We will perform a one step model assessment in this section, and in following section we will explore in detail each of the steps undergone in this assessment. The results for this
example can also be found in the folder \lstinline!precooked_runs!. In that folder you will also
find the results for the BEAST 2 run of \lstinline!sim.1.xml!.

Begin by opening R. The following will set the working directory to the
scripts folder, and then source all the functions in the folder.

\begin{lstlisting}[language=R]
    setwd("[INSERT THE PATH TO SCRIPTS FOLDER]")
    for(i in dir()) source(i)
\end{lstlisting}

Next, we set the directory to \lstinline!precooked_runs!, and run the
function \lstinline!adeq()!. The arguments for this function are the
posterior of trees in nexus format, the log file, the alignment in nexus
format, and the number of posterior predictive simulations to be
performed. You can use different path arguments if you ran your own
BEAST 2 analyses in another folder.

\begin{lstlisting}[language=R]
    setwd("../precooked_runs")
    clock_adequacy_example <- adeq(trees.file = "sim1.trees", log.file ="sim1.log", empdat.file = "../data/al.1.nex", Nsim = 100)
    names(clock_adequacy_example)
\end{lstlisting}

The contents of \lstinline!clock_adequacy_example! should appear after the final
line of code, and are each of the components that can be used to assess
clock and substitution model adequacy.

The \lstinline!clock_adequacy_example! object should have the same contents as
object ``assessment\_provided'' in the file \lstinline!results.Rdata!:

\begin{lstlisting}[language=R]
    load("results.Rdata")
    names(assessment_provided)
\end{lstlisting}

The following section describes the steps for assessing model adequacy in detail. \clearpage

\section{Steps for assessing model
adequacy}\label{steps-for-assessing-model-adequacy}

\subsection{Reading the runs and simulating
data}\label{reading-the-runs-and-simulating-data}

We will study the code in R and Figure
\ref{fig:example1} in
detail. This section is mainly for reading and discussion, and is aimed for you to cement the steps required for assessing model adequacy.

Open the \lstinline!adeq.R! file in a text editor of your preference and
you should see the following:

\begin{lstlisting}[language=R]
  adeq <- function(trees.file, log.file, empdat.file, Nsim = 100){
     empdat <- as.phyDat(as.DNAbin(read.nexus.data(empdat.file)))
     seqlen <- ncol(as.matrix(as.DNAbin(empdat)))
     tree.topo <- read.nexus(trees.file)[[1]]
     sims <- make.pps.als(trees.file, log.file, Nsim, seqlen)
     sims <- make.pps.tr(sims, empdat, tree.topo)
     bls <- compile.results(sims)
     return(bls)
 }
\end{lstlisting}

The analysis of empirical data appears in blue in Figure 
\ref{fig:example2}. We then need to read the posterior trees and parameter
estimates of the BEAST 2 analysis. The R package \emph{phangorn} allows
us to take these data and run the posterior predictive simulations, which is shown in green in Figure \ref{fig:example1}. You
will find the code to read data from the posterior and for simulating genetic alignments in
\lstinline!make.pps.als!. This script identifies the model being assessed and
simulates data accordingly. The input required in this step includes:

\begin{itemize}

\item
  The paths of the posterior files for your analysis.
\item
  The number of simulations you want to perform.
\item
  The sequence length (number of sites in your alignment).
\end{itemize}

If you are interested in how we read and simulate data in R, you
can investigate the \lstinline!make.pps.als! code. The following is the
line in \lstinline!adeq.R! in question:

\begin{lstlisting}[language=R]
    sims <- make.pps.als(trees.file, log.file, Nsim, seqlen)
\end{lstlisting}

If the input file has a greater number of samples than the number of
simulations requested, this will randomly select samples from the
posterior. This is a good moment to discuss or read about how an alignment can be simulated using data from the posterior.

\begin{figure}
    \centering
    \includegraphics[width=0.800000\textwidth]{figures/Figure_1.pdf}
    \caption{Two of the existing approaches to using posterior predictive simulations to assess model adequacy in Bayesian phylogenetics. (a) One group of methods use characteristics of the data for model assessment, like the multinomial likelihood or the GC content. (b) Another method can assess clock models using estimates from clock-free methods. Under this approach, the number of substitutions per site expected along each branch under the clock hierarchical model are compared with those inferred in a clock-free analysis of the empirical data.}
    \label{fig:example1}
\end{figure}

\clearpage

\subsubsection{Calculate test
statistics}\label{calculate-test-statistics}

Once we have simulated data sets, we can calculate the test statistics.
The function \lstinline!make.pps.trs! takes the assumed tree,
substitution model, and the empirical and simulated data sets. The
function estimates phylogenetic branch lengths for the empirical data
set and each of the simulated data sets. In this step we also estimate
the multinomial likelihood test statistic for the empirical data and
each of the simulated data sets.

\begin{lstlisting}[language=R]
    sims <- make.pps.tr(sims, empdat, tree.topo)
\end{lstlisting}

The output of this function is what we need for model assessment: the
test statistics for the empirical data, and the distribution of test
statistics for the simulated data sets.

\subsubsection{\texorpdfstring{Calculate
\emph{P}-values}{Calculate P-values}}\label{calculate-p-values}

We can now compare the test statistic for the empirical data and each of
the simulated data sets, which is the step shown in red in Figure
\ref{fig:example1}. The most common way to do this is to calculate
the tail area probability, which is the number of simulations with a
test statistic greater than the value for the empirical data.

\begin{lstlisting}[language=R]
    bls <- compile.results(sims)
\end{lstlisting}

This function will provide the test statistics for simulations, as well
as \emph{P}-values for each of the test statistics. Following practice
from frequentist statistics, we can consider the model to be inadequate
if the \emph{P}-value for a given test statistic is below 0.05.
Importantly, the assessment of the clock model allows us to identify the 
branches for which the molecular clock model can estimate the number of
substitutions. We will explore the interpretation of these data in the following section.

\section{Interpreting substitution model
assessment}\label{interpreting-substitution-model-assessment}

It is strongly recommended to use qualitative checks of models using
graphical analyses. This section uses the results in
\lstinline!precooked_runs/results.Rdata! to graph different components
for assessing clock model adequacy using posterior predictive
simulations.

We will first visualise the results for assessing substitution model
adequacy. The following code makes a histogram of the distribution of
the multinomial likelihood for the PPS data, and will show the position
of the value for empirical data on this distribution.

\begin{lstlisting}[language=R]
    hist(assessment_provided[[8]], 
         xlim = c(min(assessment_provided[[8]])-sd(assessment_provided[[8]]), 
                  max(assessment_provided[[8]])+sd(assessment_provided[[8]])), 
         main = "", xlab = "Multinomial likelihood")

    abline(v = assessment_provided[[7]], col = 2, lwd = 3)
\end{lstlisting}

Your plot will be identical or very similar to Figure
\ref{fig:example2}. When assessing model adequacy, we consider the model
to be an adequate representation of the evolutionary process if the test
statistic for the empirical data is a typical value arising from the
model. The multinomial likelihood for the empirical data falls inside
the distribution of values for simulated data (Figure
\ref{fig:example2}), so our substitution model is a good description of the process
that generated the data. This is unsurprising, since our empirical data
were actually generated under the same substitution model used for analysis!

This result can also be observed in the \emph{P}-value for the
multinomial likelihood in R:

\begin{lstlisting}[language=R]
    assessment_provided[9]
\end{lstlisting}

\begin{figure}
    \centering
    \includegraphics[width=0.700000\textwidth]{figures/Figure_2_multinomial_dist.pdf}
    \caption{Distribution of PPS multinomial likelihood values with the value of the test statistic for the empirical data shown as a vertical line in red.}
    \label{fig:example2}
\end{figure}

\subsubsection{Interpreting clock model
assessment}\label{interpreting-clock-model-assessment}

The following script shows a simple example to explore the branch-wise
posterior predictive \emph{P}-values. We will first load the tree. In
this example we will use the original tree provided, but usually the
tree with the median posterior branching times would be appropriate. We
will colour the branches with the best accuracy in blue, and the
branches that have the lowest accuracy in green (Figure
\ref{fig:example3}).

\begin{lstlisting}[language=R]
   tr <- read.tree("../data/chrono.tre")
   plot(tr, edge.col = rainbow(length(assessment_provided$branch_wise_pppvalues), 
        start = 2/6, end = 4/6)[rank(assessment_provided$branch_wise_pppvalues)], 
        edge.width = 6, cex = 1.5)
   edgelabels(assessment_provided$branch_wise_pppvalues, bg = "white", cex = 1.5, frame = "none")
\end{lstlisting}

The values along each branch indicate the proportion of simulations in which
the branch-length was greater than the length estimated using the
empirical data. The expected value under the model is 0.5. If this value
is 0 branch-lengths are being underestimated with respect to the model.
Similarly, if the value is 1 branch-lengths are being overestimated with
respect to the model.

You can also investigate the $ A $ index:

\begin{lstlisting}[language=R]
   assessment_provided[4]
\end{lstlisting}

This index is the proportion of branches in the tree for which the
branch-wise posterior predictive \emph{P}-values are inside the central
95 percent of the distribution. The rates and times models can be
considered adequate when the $ A $ index is high.

You might find it surprising that the $ A $ index in these
data is not so close to 1. The reason for this might be evident when you
open the data alignment in a text editor. These data have a very large
amount of variation, and have possibly undergone substantial
substitutional saturation. For comparison, you might want to repeat all
of the analyses, or explore the provided results for the second data set
provided, \lstinline!al.2.nex!. This data set evolved through the same
tree but with lower rates of molecular evolution.

\begin{figure}
    \centering
    \includegraphics[width=0.900000\textwidth]{figures/Figure_3_branchwise_p.pdf}
    \caption{Estimated chronogram with branches coloured by their clock adequacy P-value.}
    \label{fig:example3}
\end{figure}

The following script shows a simple example to explore the branch-wise
length deviation. This metric is a proxy for the difference between the
branch-length estimate using empirical data and the mean branch-length
estimate using posterior predictive simulations. To make the values comparable across branches, the difference between the empirical branch-length and mean PPS branch-length has been divided by the empirical branch length.
If this value is close to zero, the priors for times and molecular evolutionary rates can be considered adequate. We
apply the same colouring system as the plot above, but note that in the
case of branch length deviation larger numbers indicate greater
deviation from the empirical branch length, and therefore lower accuracy
(Figure \ref{fig:example4}).

\begin{lstlisting}[language=R]
    plot(tr, edge.col = rev(rainbow(length(assessment_provided$branch_length_deviation), 
         start = 2/6, end = 4/6)[rank(assessment_provided$branch_length_deviation)]), 
         edge.width = 6, cex = 1.5)
    edgelabels(round(assessment_provided$branch_length_deviation, 2), bg = "white", cex = 1.5, frame = "none")
\end{lstlisting}

\begin{figure}
    \centering
    \includegraphics[width=0.900000\textwidth]{figures/Figure_4_branchwise_dev.pdf}
    \caption{Estimated chronogram with branches coloured by their deviation between the empirical and simulated lengths.}
    \label{fig:example4}
\end{figure}

Note that in this simple method to graph the results, the branches in
the two plots above have been coloured by their rank, rather than their
magnitude.

\clearpage



%%%%%%%%%%%%%%%%%%%%%%%
% Tutorial disclaimer %
%%%%%%%%%%%%%%%%%%%%%%%
% Please do not change the license
% Add the author names and relevant links
% Add any other aknowledgments here
\href{http://creativecommons.org/licenses/by/4.0/}{\includegraphics[scale=0.8]{figures/ccby.pdf}} This tutorial was written by David Duchêne for \href{https://taming-the-beast.github.io}{Taming the BEAST} and is licensed under a \href{http://creativecommons.org/licenses/by/4.0/}{Creative Commons Attribution 4.0 International License}. 


%%%%%%%%%%%%%%%%%%%%
% Do NOT edit this %
%%%%%%%%%%%%%%%%%%%%
Version dated: \today



\newpage

%%%%%%%%%%%%%%%%
%  REFERENCES  %
%%%%%%%%%%%%%%%%

\nocite{*}
\printbibliography[heading=relevref]


\end{document}
